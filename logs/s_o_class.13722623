Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz
   16384/11490434 [..............................] - ETA: 0s 1818624/11490434 [===>..........................] - ETA: 0s 2105344/11490434 [====>.........................] - ETA: 0s 4128768/11490434 [=========>....................] - ETA: 0s 6168576/11490434 [===============>..............] - ETA: 0s 6692864/11490434 [================>.............] - ETA: 0s 8708096/11490434 [=====================>........] - ETA: 0s10739712/11490434 [===========================>..] - ETA: 0s11493376/11490434 [==============================] - 0s 0us/step
11501568/11490434 [==============================] - 0s 0us/step
/users/k1461892/.conda/envs/variational_orthogonal_classifiers/lib/python3.8/site-packages/numba/np/ufunc/parallel.py:365: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 6103. The TBB threading layer is disabled.
  warnings.warn(problem)
  0%|          | 0/1 [00:00<?, ?it/s]  0%|          | 0/1 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "experiments.py", line 356, in <module>
    all_classes_experiment(
  File "experiments.py", line 253, in all_classes_experiment
    classifier_opt = optmzr.optimize(1)
  File "/users/k1461892/.conda/envs/variational_orthogonal_classifiers/lib/python3.8/site-packages/quimb/tensor/optimize.py", line 1217, in optimize
    self.res = minimize(
  File "/users/k1461892/.conda/envs/variational_orthogonal_classifiers/lib/python3.8/site-packages/scipy/optimize/_minimize.py", line 600, in minimize
    return method(fun, x0, args=args, jac=jac, hess=hess, hessp=hessp,
  File "/users/k1461892/.conda/envs/variational_orthogonal_classifiers/lib/python3.8/site-packages/quimb/tensor/optimize.py", line 794, in __call__
    g = jac(x)
  File "/users/k1461892/.conda/envs/variational_orthogonal_classifiers/lib/python3.8/site-packages/scipy/optimize/optimize.py", line 78, in derivative
    self._compute_if_needed(x, *args)
  File "/users/k1461892/.conda/envs/variational_orthogonal_classifiers/lib/python3.8/site-packages/scipy/optimize/optimize.py", line 68, in _compute_if_needed
    fg = self.fun(x, *args)
  File "/users/k1461892/.conda/envs/variational_orthogonal_classifiers/lib/python3.8/site-packages/quimb/tensor/optimize.py", line 1089, in vectorized_value_and_grad
    result, grads = self.handler.value_and_grad(arrays)
  File "/users/k1461892/.conda/envs/variational_orthogonal_classifiers/lib/python3.8/site-packages/quimb/tensor/optimize.py", line 339, in value_and_grad
    loss, grads = self._value_and_grad(arrays)
  File "/users/k1461892/.conda/envs/variational_orthogonal_classifiers/lib/python3.8/site-packages/autograd/wrap_util.py", line 20, in nary_f
    return unary_operator(unary_f, x, *nary_op_args, **nary_op_kwargs)
  File "/users/k1461892/.conda/envs/variational_orthogonal_classifiers/lib/python3.8/site-packages/autograd/differential_operators.py", line 135, in value_and_grad
    vjp, ans = _make_vjp(fun, x)
  File "/users/k1461892/.conda/envs/variational_orthogonal_classifiers/lib/python3.8/site-packages/autograd/core.py", line 10, in make_vjp
    end_value, end_node =  trace(start_node, fun, x)
  File "/users/k1461892/.conda/envs/variational_orthogonal_classifiers/lib/python3.8/site-packages/autograd/tracer.py", line 10, in trace
    end_box = fun(start_box)
  File "/users/k1461892/.conda/envs/variational_orthogonal_classifiers/lib/python3.8/site-packages/autograd/wrap_util.py", line 15, in unary_f
    return fun(*subargs, **kwargs)
  File "/users/k1461892/.conda/envs/variational_orthogonal_classifiers/lib/python3.8/site-packages/quimb/tensor/optimize.py", line 870, in __call__
    return self.loss_fn(self.norm_fn(tn_compute))
  File "/mnt/lustre/users/k1461892/Orthogonal_Classifiers/variational_mpo_classifiers.py", line 370, in orthogonalise_and_normalize
    tn = compress_QTN(tn, D=None, orthogonalise=True)
  File "/mnt/lustre/users/k1461892/Orthogonal_Classifiers/variational_mpo_classifiers.py", line 192, in compress_QTN
    QTN_to_fMPO(projected_q_mpo).compress(D=D, orthogonalise=orthogonalise)
  File "/mnt/lustre/users/k1461892/Orthogonal_Classifiers/fMPO_reduced.py", line 178, in compress
    A, S, V = split(self[m])
  File "/mnt/lustre/users/k1461892/Orthogonal_Classifiers/fMPO_reduced.py", line 90, in split
    M = datum.transpose(0, 2, 1, 3).reshape(d * i, s * j)
  File "/users/k1461892/.conda/envs/variational_orthogonal_classifiers/lib/python3.8/site-packages/autograd/tracer.py", line 44, in f_wrapped
    ans = f_wrapped(*argvals, **kwargs)
  File "/users/k1461892/.conda/envs/variational_orthogonal_classifiers/lib/python3.8/site-packages/autograd/tracer.py", line 48, in f_wrapped
    return f_raw(*args, **kwargs)
  File "<__array_function__ internals>", line 4, in transpose
TypeError: _transpose_dispatcher() takes from 1 to 2 positional arguments but 5 were given
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpirun detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[17852,1],0]
  Exit code:    1
--------------------------------------------------------------------------
finished
